import os
from pyannote.audio import Pipeline
import speech_recognition as sr
from moviepy.editor import AudioFileClip
from transformers import pipeline
from textblob import TextBlob
from utils import diarize_text  # Importing the diarize_text function

# Disable symlink warnings
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
os.environ["HF_HOME"] = "D:/video_summarisation/cache"  # Custom cache directory

# Set Hugging Face authentication token
os.environ["HUGGING_FACE_HUB_TOKEN"] = "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"

# Initialize the speaker diarization pipeline
diarization_pipeline = Pipeline.from_pretrained(
    "pyannote/speaker-diarization",
    use_auth_token=os.getenv("HUGGING_FACE_HUB_TOKEN")
)

# Initialize the summarization pipeline
summarizer = pipeline("summarization", model="t5-small")

# Convert MP3 to WAV function
def convert_mp3_to_wav(mp3_file, wav_file):
    audio_clip = AudioFileClip(mp3_file)
    audio_clip.write_audiofile(wav_file, codec='pcm_s16le')

# Transcription function
def transcribe_chunk(chunk_file, recognizer, language_code="en-US"):
    with sr.AudioFile(chunk_file) as source:
        recognizer.adjust_for_ambient_noise(source)
        audio_data = recognizer.record(source)
        return recognizer.recognize_google(audio_data, language=language_code)

# Sentiment Analysis function
def analyze_sentiment(text):
    blob = TextBlob(text)
    polarity = blob.sentiment.polarity
    subjectivity = blob.sentiment.subjectivity
    if polarity > 0.1:
        tone = "Positive"
    elif polarity < -0.1:
        tone = "Negative"
    else:
        tone = "Neutral"
    return polarity, subjectivity, tone

# Genre Detection function
def detect_genre(text):
    text = text.lower()
    genres = {
        "Meeting": ["meeting", "agenda", "discussion"],
        "Sports": ["sports", "game", "match", "team", "score"],
        "Music": ["music", "song", "lyrics", "melody", "rhythm", "tune"],
        "News": ["news", "report", "breaking", "headline"],
        "Interview": ["interview", "question", "answer", "guest"],
        "Technology": ["model", "technology", "software", "hardware", "device", "innovation"],
        "Business": ["business", "market", "profit", "revenue", "finance"]
    }
    for genre, keywords in genres.items():
        if any(keyword in text for keyword in keywords):
            return genre
    return "General"

# Simple Plan of Action Generator
def generate_simple_plan_of_action(transcript):
    actions = ["Follow up on", "Discuss", "Assign", "Review"]
    plan = []
    
    if "next steps" in transcript or "to do" in transcript:
        plan.append("List next steps and responsible persons.")
    if "project" in transcript:
        plan.append("Review project timeline and deliverables.")
    if "budget" in transcript or "finance" in transcript:
        plan.append("Analyze current budget and assess financial requirements.")
    if "client" in transcript:
        plan.append("Summarize client feedback and improvement areas.")
    
    if not plan:
        plan.append("Summarize key action points discussed in the meeting.")
    
    return "\n".join(f"- {action}" for action in plan)

# Main processing function
def process_audio(mp3_file_path, transcription_file_path, language_code="en-US"):
    # Convert mp3 to wav
    wav_file_path = "converted_audio.wav"
    convert_mp3_to_wav(mp3_file_path, wav_file_path)
    
    # Run diarization
    diarization_result = diarization_pipeline({"uri": "audio", "audio": wav_file_path})

    # Initialize recognizer
    recognizer = sr.Recognizer()
    speaker_segments = []
    transcription_result = []

    # Process each speaker segment from diarization
    for turn, _, speaker in diarization_result.itertracks(yield_label=True):
        audio_segment = AudioFileClip(wav_file_path).subclip(turn.start, turn.end)
        segment_path = f"segment_{speaker}_{int(turn.start)}.wav"
        audio_segment.write_audiofile(segment_path, codec='pcm_s16le')
        
        # Transcribe segment
        transcription = transcribe_chunk(segment_path, recognizer, language_code)
        transcription_result.append((turn, speaker, transcription))
        
        # Clean up segment file
        os.remove(segment_path)

    # Use diarize_text to combine speaker labels and transcriptions
    final_result = diarize_text(transcription_result, diarization_result)

    # Detect genre
    full_transcription = " ".join([sent for _, _, sent in final_result])
    genre = detect_genre(full_transcription)

    # Sentiment Analysis
    polarity, subjectivity, tone = analyze_sentiment(full_transcription)

    # Summarization
    summary_text = summarizer(full_transcription, max_length=100, min_length=30, do_sample=False)[0]['summary_text']

    # If the genre is "Meeting", generate a simple plan of action
    plan_of_action = ""
    if genre == "Meeting":
        plan_of_action = generate_simple_plan_of_action(full_transcription)

    # Count unique speakers
    unique_speakers = set(speaker for _, speaker, _ in final_result)
    number_of_speakers = len(unique_speakers)

    # Save all information to a file
    with open(transcription_file_path, "w") as file:
        file.write("Summary of Conversation:\n")
        file.write(summary_text + "\n\n")
        
        file.write("Detected Genre: " + genre + "\n\n")

        if plan_of_action:
            file.write("Plan of Action:\n" + plan_of_action + "\n\n")
        
        file.write(f"Number of Speakers: {number_of_speakers}\n\n")
        
        file.write("Speaker-wise Transcriptions:\n")
        for seg, spk, sent in final_result:
            line = f"{seg.start:.2f} {seg.end:.2f} {spk} {sent}"
            print(line)  # Output to console for verification
            file.write(line + '\n')  # Append to the transcription file
        
        file.write("\nOverall Sentiment Analysis:\n")
        file.write(f"Polarity: {polarity}\n")
        file.write(f"Subjectivity: {subjectivity}\n")
        file.write(f"Tone: {tone}\n")
    
    print(f"Transcription, summary, genre, plan of action, and sentiment analysis saved to {transcription_file_path}")
    os.remove(wav_file_path)
    
    return summary_text  # Return the summary text for further processing or display

# Example usage
mp3_file_path = input("Enter the path to your MP3 file: ")
transcription_file_path = "transcription.txt"
language_code = "en-US"

# Process the audio file
summary = process_audio(mp3_file_path, transcription_file_path, language_code)
print("Extracted Summary:", summary)
